{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset download\n",
    "mnist_train = dsets.MNIST(root = \"MNIST_data/\", train = True, transform=transforms.ToTensor(), download = True)\n",
    "mnist_test = dsets.MNIST(root = \"MNIST_data/\", train = False, transform=transforms.ToTensor(), download = True)\n",
    "\n",
    "fashion_train = dsets.FashionMNIST(root = \"Fashion_data\", train = True, transform=transforms.ToTensor(), download= True)\n",
    "fashion_test = dsets.FashionMNIST(root = \"Fashion_data\", train = False, transform=transforms.ToTensor(), download= True)\n",
    "\n",
    "\n",
    "\n",
    "# train과 test directory로 담기\n",
    "# 2000개씩 담아내면 됌 -> 2000개 * 20(클래스) = 40,000개 데이터\n",
    "\n",
    "# 그리고 나머지 것들중 100개씩 test로 담는다고 생각해보자.\n",
    "# 100개씩 담아내면 됌 -> 100개 * 20(클래스) = 2,000개 데이터\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom한 데이터셋을 만들고, 정규화를 시켜봅시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# dataset만들기\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y, transform = None):\n",
    "        self.x_data = X\n",
    "        self.y_data = Y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # x,y가 이미 Tensor Type으로 존재함.\n",
    "\n",
    "        x = self.x_data[idx]\n",
    "        y = self.y_data[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            y = self.transform(y)\n",
    "     \n",
    "        \n",
    "        return x,y\n",
    "\n",
    "# transform\n",
    "'''\n",
    "질문: 왜 255를 나누는 것일까?\n",
    "\n",
    "mnist_train.data.float().mean() / 255\n",
    "mnist_train.data.float().std() / 255\n",
    "\n",
    "'''\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1306), (0.3081))\n",
    "])\n",
    "    \n",
    "dataset = CustomDataset(mnist_train.data, mnist_train.targets, transform = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = (mnist_train.data.float().mean() /255 + fashion_train.data.float().mean() /255) /2\n",
    "std = (mnist_train.data.float().std() / 255 + fashion_train.data.float().std() /255) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3530)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_train.data.float().std() /255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 순서를 다시 세워보자.\n",
    "(1) 일단 데이터를 저장하는게 먼저이고, (2) 그 다음에 커스텀 데이터셋을 만들고, (3)데이터 로더를 만드는 과정이구나."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset download\n",
    "mnist_train = dsets.MNIST(root = \"MNIST_data/\", train = True, transform=transforms.ToTensor(), download = True)\n",
    "mnist_test = dsets.MNIST(root = \"MNIST_data/\", train = False, transform=transforms.ToTensor(), download = True)\n",
    "\n",
    "fashion_train = dsets.FashionMNIST(root = \"Fashion_data\", train = True, transform=transforms.ToTensor(), download= True)\n",
    "fashion_test = dsets.FashionMNIST(root = \"Fashion_data\", train = False, transform=transforms.ToTensor(), download= True)\n",
    "\n",
    "\n",
    "\n",
    "# train과 test directory로 담기\n",
    "# 2000개씩 담아내면 됌 -> 2000개 * 20(클래스) = 40,000개 데이터\n",
    "\n",
    "# 그리고 나머지 것들중 100개씩 test로 담는다고 생각해보자.\n",
    "# 100개씩 담아내면 됌 -> 100개 * 20(클래스) = 2,000개 데이터\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imags = [1]*21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mnist데이터 저장.\n",
    "num_imags = [1]*21\n",
    "for sample in mnist_train:\n",
    "    img, label = sample\n",
    "    if num_imags[label] > 2000:\n",
    "        continue\n",
    "    \n",
    "    # tensor를 이미지로 변환\n",
    "    PIL_img = transforms.ToPILImage()(img)\n",
    "    # 클래스번호/사진번호로 저장\n",
    "    PIL_img.save(\"./train/%d/%d.jpeg\"%(label,num_imags[label]))\n",
    "    # 카운트\n",
    "    num_imags[label] += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion_mnist 저장.\n",
    "for sample in fashion_train:\n",
    "    img,label = sample\n",
    "    label += 10\n",
    "    if num_imags[label] > 2000:\n",
    "        continue\n",
    "    \n",
    "    PIL = transforms.ToPILImage()(img)\n",
    "    PIL.save('./train/%d/%d.jpeg'%(label, num_imags[label]))\n",
    "    num_imags[label] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[981, 1001, 1001, 1001, 983, 893, 959, 1001, 975, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_images = [1]*21\n",
    "for sample in mnist_test:\n",
    "    img, label = sample\n",
    "    if test_images[label] > 1000:\n",
    "        continue\n",
    "    \n",
    "    PIL = transforms.ToPILImage()(img)\n",
    "    PIL.save(\"./test/%d/%d.jpeg\"%(label, test_images[label]))\n",
    "    test_images[label] += 1\n",
    "\n",
    "for sample in fashion_test:\n",
    "    img, label = sample\n",
    "    label += 10\n",
    "    if test_images[label] > 1000:\n",
    "        continue\n",
    "    PIL2 = transforms.ToPILImage()(img)\n",
    "    PIL2.save(\"./test/%d/%d.jpeg\"%(label, test_images[label]))\n",
    "    test_images[label] += 1\n",
    "\n",
    "print(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Folder를 이용해서, 해당 데이터를 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageFolder 이용\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root = \"./train/\", transform = transforms.ToTensor())\n",
    "test_data = torchvision.datasets.ImageFolder(root = \"./test/\", transform = transforms.ToTensor())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_data, batch_size = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-ec0547c1bf64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

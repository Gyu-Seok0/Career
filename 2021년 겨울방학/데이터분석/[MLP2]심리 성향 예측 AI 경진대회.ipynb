{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지난 시간 결과\n",
    "0.49정도의 결과를 가졌다\n",
    "--> 정말 대충 짠 코드인데 절반을 맞췄다는게 신기하다\n",
    "\n",
    "# Feedback\n",
    "1) feature engineering\n",
    "--> 어떤 feature들이 주요한 역할을 하는가?\n",
    "\n",
    "2) 데이터 정규화\n",
    "--> min-max, stardarization\n",
    "\n",
    "3) MLP \n",
    "--> 다른 알고리즘들은 어떤게 있을까?\n",
    "--> 파이토치로 구성해보는 건 어떨까?\n",
    "\n",
    "4) threshold\n",
    "--> 1.5를 기준으로해서 잡았는데, 이것은 무엇을 기준으로 잡을 수 있을까?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Feature engineering\n",
    "1) object변수들을 원핫인코딩으로 바꿔주겠다.\n",
    "<br>\n",
    "2) 좋은 Feature이 무엇인지 search해보자<br>\n",
    "<i style =\"border: 1px solid black;\"> Feature Engineering이란 머신러닝 문제에 대해서 타겟에 대해서 최고로 잘 표현할 수 있게 가공되지 않은 데이터를 가공하는 것을 의미한다. <i>\n",
    "<br>\n",
    "1. You can isolate and highlight key information, which helps your algorithms “focus” on what’s important.\n",
    "중요하다고 생각하는 변수를 강조시킬 수 있다.\n",
    "\n",
    "2. You can bring in your own domain of expertise.\n",
    "자신만의 도메인을 도입할 수 있다.\n",
    "\n",
    "3. Most importantly, once you understand the “vocabulary” of feature engineering, you can bring in other people’s domain expertise!\n",
    "<br>https://data-newbie.tistory.com/93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>QeE</th>\n",
       "      <th>...</th>\n",
       "      <th>wr_04</th>\n",
       "      <th>wr_05</th>\n",
       "      <th>wr_06</th>\n",
       "      <th>wr_07</th>\n",
       "      <th>wr_08</th>\n",
       "      <th>wr_09</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>736</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2941</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2550</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>514</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1952</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1552</td>\n",
       "      <td>3.0</td>\n",
       "      <td>821</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2507</td>\n",
       "      <td>4.0</td>\n",
       "      <td>480</td>\n",
       "      <td>2.0</td>\n",
       "      <td>614</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1326</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1050</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1435</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2533</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1243</td>\n",
       "      <td>5.0</td>\n",
       "      <td>845</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1666</td>\n",
       "      <td>2.0</td>\n",
       "      <td>925</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   QaA  QaE  QbA   QbE  QcA   QcE  QdA   QdE  QeA   QeE  ...  wr_04  wr_05  \\\n",
       "0  3.0  736  2.0  2941  3.0  4621  1.0  4857  2.0  2550  ...      0      1   \n",
       "1  3.0  514  2.0  1952  3.0  1552  3.0   821  4.0  1150  ...      0      0   \n",
       "2  3.0  500  2.0  2507  4.0   480  2.0   614  2.0  1326  ...      0      1   \n",
       "3  1.0  669  1.0  1050  5.0  1435  2.0  2252  5.0  2533  ...      1      1   \n",
       "4  2.0  499  1.0  1243  5.0   845  2.0  1666  2.0   925  ...      1      1   \n",
       "\n",
       "   wr_06  wr_07  wr_08  wr_09  wr_10  wr_11  wr_12  wr_13  \n",
       "0      0      0      1      0      1      0      1      1  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      1      1      0      1      0      1      1  \n",
       "3      1      1      1      1      1      1      1      1  \n",
       "4      0      1      1      0      1      1      1      1  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 데이터 불러오기\n",
    "train = pd.read_csv(\"/Users/igyuseog/Desktop/open data/train.csv\")\n",
    "test = pd.read_csv(\"/Users/igyuseog/Desktop/open data/test_x.csv\")\n",
    "\n",
    "# 첫번째 열에 해당하는 (index)를 지웠다.\n",
    "train = train.iloc[:,1:]\n",
    "test = test.iloc[:,1:]\n",
    "\n",
    "#출력\n",
    "train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#object인 column명을 알 수 있다.\n",
    "object_col = train.columns[train.dtypes == \"object\"].tolist()\n",
    "\n",
    "#groupby (다양한 기능들이 존재하는데, 내가 원했던건 그룹별로 voted의 양상이었다.)\n",
    "train.groupby([\"gender\"])[\"voted\"].value_counts()\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "#step1) drop --> 필요없다고 판단되는 것들을 지웠다.\n",
    "y = train[\"voted\"]\n",
    "train = train.drop([\"engnat\",\"hand\",\"race\",\"religion\",\"urban\",\"voted\"], axis = 1)\n",
    "test = test.drop([\"engnat\",\"hand\",\"race\",\"religion\",\"urban\"], axis = 1)\n",
    "\n",
    "#step2)one_hot encoding은 아래와 같이 get_dumpy를 통해 가능하다.\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "#step3) 정규화 min-max\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "train = min_max_scaler.fit_transform(train)\n",
    "test = min_max_scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "model = MLPRegressor(hidden_layer_sizes = [10,10,10,10,10]).fit(train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.6836730211719231\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pred = model.predict(train)\n",
    "pred = np.where(pred < 1.483,1,2)\n",
    "\n",
    "acc = sum(pred == y) / len(pred)\n",
    "print(\"accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"/Users/igyuseog/Desktop/open data/sample_submission.csv\")\n",
    "pred = model.predict(test)\n",
    "pred = np.where(pred < 1.483,1,2)\n",
    "\n",
    "submit[\"voted\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.loc[:,\"voted\"].to_csv(\"/Users/igyuseog/Desktop/open data/MLP2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dacon 75위 참고자료\n",
    "https://dacon.io/competitions/official/235647/codeshare/1819?page=1&dtype=recent&ptype=pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45532, 78)\n",
      "(45529, 78)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/Users/igyuseog/Desktop/open data/train.csv\")\n",
    "train = train.drop(train[train[\"familysize\"] > 50].index)\n",
    "test = pd.read_csv(\"/Users/igyuseog/Desktop/open data/test_x.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        QaA  QbA  QcA  QdA  QeA  QfA  QgA  QhA  QiA  QjA  ...  \\\n",
      "0      3.0  4.0  5.0  1.0  2.0  5.0  2.0  4.0  5.0  4.0  ...   \n",
      "1      5.0  5.0  3.0  5.0  1.0  3.0  1.0  1.0  5.0  3.0  ...   \n",
      "2      4.0  1.0  1.0  4.0  5.0  1.0  4.0  1.0  3.0  2.0  ...   \n",
      "3      3.0  3.0  4.0  3.0  1.0  2.0  4.0  3.0  5.0  4.0  ...   \n",
      "4      1.0  1.0  5.0  2.0  1.0  2.0  1.0  1.0  5.0  5.0  ...   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "45527  2.0  5.0  4.0  1.0  1.0  1.0  1.0  1.0  1.0  4.0  ...   \n",
      "45528  2.0  3.0  4.0  1.0  3.0  2.0  2.0  1.0  2.0  5.0  ...   \n",
      "45529  4.0  1.0  1.0  4.0  5.0  4.0  5.0  1.0  5.0  1.0  ...   \n",
      "45530  1.0  3.0  4.0  2.0  1.0  1.0  1.0  1.0  5.0  1.0  ...   \n",
      "45531  3.0  5.0  5.0  3.0  1.0  4.0  3.0  3.0  4.0  4.0  ...   \n",
      "\n",
      "       religion_Christian_Protestant  religion_Hindu  religion_Jewish  \\\n",
      "0                                  0               0                0   \n",
      "1                                  0               1                0   \n",
      "2                                  0               0                0   \n",
      "3                                  0               1                0   \n",
      "4                                  0               0                0   \n",
      "...                              ...             ...              ...   \n",
      "45527                              0               0                1   \n",
      "45528                              0               0                0   \n",
      "45529                              0               0                0   \n",
      "45530                              0               0                0   \n",
      "45531                              0               0                0   \n",
      "\n",
      "       religion_Muslim  religion_Other  religion_Sikh  urban_0  urban_1  \\\n",
      "0                    0               1              0        0        1   \n",
      "1                    0               0              0        0        0   \n",
      "2                    0               1              0        0        0   \n",
      "3                    0               0              0        0        0   \n",
      "4                    0               0              0        0        1   \n",
      "...                ...             ...            ...      ...      ...   \n",
      "45527                0               0              0        0        0   \n",
      "45528                0               0              0        0        1   \n",
      "45529                0               0              0        0        0   \n",
      "45530                0               0              0        1        0   \n",
      "45531                0               0              0        0        0   \n",
      "\n",
      "       urban_2  urban_3  \n",
      "0            0        0  \n",
      "1            0        1  \n",
      "2            1        0  \n",
      "3            0        1  \n",
      "4            0        0  \n",
      "...        ...      ...  \n",
      "45527        0        1  \n",
      "45528        0        0  \n",
      "45529        1        0  \n",
      "45530        0        0  \n",
      "45531        1        0  \n",
      "\n",
      "[45529 rows x 91 columns]>\n"
     ]
    }
   ],
   "source": [
    "drop_list = ['QaE', 'QbE', 'QcE', 'QdE', 'QeE',\n",
    "             'QfE', 'QgE', 'QhE', 'QiE', 'QjE',\n",
    "             'QkE', 'QlE', 'QmE', 'QnE', 'QoE',\n",
    "             'QpE', 'QqE', 'QrE', 'QsE', 'QtE',\n",
    "             'index', 'hand']\n",
    "replace_dict = {'education': str, 'engnat': str, 'married': str, 'urban': str}\n",
    "\n",
    "train_y = train[\"voted\"]\n",
    "train_x = train.drop(drop_list + [\"voted\"], axis = 1)\n",
    "test_x = test.drop(drop_list, axis = 1)\n",
    "\n",
    "#타입 변경\n",
    "train_x = train_x.astype(replace_dict)\n",
    "test_x = test_x.astype(replace_dict)\n",
    "#원핫인코딩\n",
    "train_x = pd.get_dummies(train_x)\n",
    "test_x = pd.get_dummies(test_x)\n",
    "print(train_x.head)\n",
    "#numpy\n",
    "train_y = 2 - train_y.to_numpy() #0이 투표한다. 1이 투표 안한다 \n",
    "train_x = train_x.to_numpy()\n",
    "test_x = test_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-71b0a20b823f>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y = torch.tensor(train_y, dtype = torch.float32)\n",
      "<ipython-input-38-71b0a20b823f>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x = torch.tensor(train_x, dtype = torch.float32)\n",
      "<ipython-input-38-71b0a20b823f>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x = torch.tensor(test_x, dtype = torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# 정규화\n",
    "train_x[:,:20] = (train_x[:,:20] -3.) / 2.\n",
    "test_x[:,:20] = (test_x[:,:20] -3.) / 2.\n",
    "\n",
    "train_x[:,20] = (train_x[:,20] -5.) / 5.\n",
    "test_x[:,20] = (test_x[:,20] -5.) / 5.\n",
    "\n",
    "train_x[:,21:31] = (train_x[:, 21:31] - 3.5) / 3.5\n",
    "test_x[:,21:31] = (test_x[:, 21:31] - 3.5) / 3.5\n",
    "# 여기서 tensor로 바꿔주는 구나.\n",
    "train_y = torch.tensor(train_y, dtype = torch.float32)\n",
    "train_x = torch.tensor(train_x, dtype = torch.float32)\n",
    "test_x = torch.tensor(test_x, dtype = torch.float32)\n",
    "train_len, test_len = len(train_x), len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MODEL = 10\n",
    "N_EPOCH = 50\n",
    "BATCH_SIZE = 128\n",
    "LOADER_PARAM = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True\n",
    "}\n",
    "\n",
    "prediction = np.zeros((11383,1), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for no in range(N_MODEL):\n",
    "    train_loader = DataLoader(TensorDataset(train_x,train_y),\n",
    "                             shuffle = True, drop_last = True, **LOADER_PARAM)\n",
    "    test_loader = DataLoader(TensorDataset(test_x, torch.zeros((test_len,), dtype = torch.float32)),\n",
    "                            shuffle = False, drop_last = False, **LOADER_PARAM)\n",
    "    model = nn.Sequential(\n",
    "        nn.Dropout(0.06),\n",
    "        nn.Linear(91,96, bias = False),\n",
    "        nn.LeakyReLU(0.05, inplace= True),\n",
    "        \n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(96,36, bias = False),\n",
    "        nn.ReLU(inplace= True),\n",
    "        \n",
    "        nn.Linear(36,1)\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight = torch.tensor([1.20665], device = DEVICE))\n",
    "    optimizer = optim.AdamW(model.parameters(), lr = 1e-3, weight_decay = 4e-2)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0= N_EPOCH // 4, eta_min = 1.2e-5)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 / 10: 100%|██████████| 50/50 [01:11<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in tqdm(range(N_EPOCH), desc = '{:02d} / {:02d}'.format(no + 1, N_MODEL)):\n",
    "    for idx, (xx,yy) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        xx,yy = xx.to(DEVICE) , yy.to(DEVICE)\n",
    "        pred = model(xx).squeeze()\n",
    "        loss = criterion(pred, yy)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch + idx / len(train_loader))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (xx,_) in enumerate(test_loader):\n",
    "        xx = xx.to(DEVICE)\n",
    "        pred = (2. - torch.sigmoid(model(xx).detach().to('cpu'))).numpy()\n",
    "        prediction[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction)), :] \\\n",
    "                += pred[:, :] / N_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15166652],\n",
       "       [0.18116131],\n",
       "       [0.14082035],\n",
       "       ...,\n",
       "       [0.12067059],\n",
       "       [0.12988257],\n",
       "       [0.16335401]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "01/07: 100%|██████████| 48/48 [02:19<00:00,  2.91s/it]\n",
      "02/07: 100%|██████████| 48/48 [02:30<00:00,  3.13s/it]\n",
      "03/07: 100%|██████████| 48/48 [02:25<00:00,  3.03s/it]\n",
      "04/07: 100%|██████████| 48/48 [02:08<00:00,  2.68s/it]\n",
      "05/07: 100%|██████████| 48/48 [02:15<00:00,  2.82s/it]\n",
      "06/07: 100%|██████████| 48/48 [02:07<00:00,  2.66s/it]\n",
      "07/07: 100%|██████████| 48/48 [02:30<00:00,  3.14s/it]\n",
      "01/07:   0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1 -> 0.6054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07:  73%|███████▎  | 35/48 [01:41<00:37,  2.91s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-7c25838ed158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{:02d}/{:02d}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskfold\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_SKFOLD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfd_event_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_EVENT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m                 \u001b[0mevents\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mEVENT_WRITE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_EVENT_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "drop_list = ['QaE', 'QbE', 'QcE', 'QdE', 'QeE',\n",
    "             'QfE', 'QgE', 'QhE', 'QiE', 'QjE',\n",
    "             'QkE', 'QlE', 'QmE', 'QnE', 'QoE',\n",
    "             'QpE', 'QqE', 'QrE', 'QsE', 'QtE',\n",
    "             'index', 'hand']\n",
    "replace_dict = {'education': str, 'engnat': str, 'married': str, 'urban': str}\n",
    "train_data = pd.read_csv(\"/Users/igyuseog/Desktop/open data/train.csv\")\n",
    "test_data = pd.read_csv(\"/Users/igyuseog/Desktop/open data/test_x.csv\")\n",
    "\n",
    "train_data = train_data.drop(train_data[train_data.familysize > 50].index)\n",
    "train_y = train_data['voted']\n",
    "train_x = train_data.drop(drop_list + ['voted'], axis=1)\n",
    "test_x = test_data.drop(drop_list, axis=1)\n",
    "train_x = train_x.astype(replace_dict)\n",
    "test_x = test_x.astype(replace_dict)\n",
    "train_x = pd.get_dummies(train_x)\n",
    "test_x = pd.get_dummies(test_x)\n",
    "train_y = 2 - train_y.to_numpy()\n",
    "train_x = train_x.to_numpy()\n",
    "test_x = test_x.to_numpy()\n",
    "\n",
    "train_y_t = torch.tensor(train_y, dtype=torch.float32)\n",
    "train_x_t = torch.tensor(train_x, dtype=torch.float32)\n",
    "test_x_t = torch.tensor(test_x, dtype=torch.float32)\n",
    "train_x_t[:, :20] = (train_x_t[:, :20] - 3.) / 2.\n",
    "test_x_t[:, :20] = (test_x_t[:, :20] - 3.) / 2\n",
    "train_x_t[:, 20] = (train_x_t[:, 20] - 5.) / 4.\n",
    "test_x_t[:, 20] = (test_x_t[:, 20] - 5.) / 4.\n",
    "train_x_t[:, 21:31] = (train_x_t[:, 21:31] - 3.5) / 3.5\n",
    "test_x_t[:, 21:31] = (test_x_t[:, 21:31] - 3.5) / 3.5\n",
    "test_len = len(test_x_t)\n",
    "\n",
    "N_REPEAT = 5\n",
    "N_SKFOLD = 7\n",
    "N_EPOCH = 48\n",
    "BATCH_SIZE = 72\n",
    "LOADER_PARAM = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True\n",
    "}\n",
    "prediction = np.zeros((test_len, 1), dtype=np.float32)\n",
    "\n",
    "for repeat in range(N_REPEAT):\n",
    "\n",
    "    skf, tot = StratifiedKFold(n_splits=N_SKFOLD, random_state=repeat, shuffle=True), 0.\n",
    "    for skfold, (train_idx, valid_idx) in enumerate(skf.split(train_x, train_y)):\n",
    "        train_idx, valid_idx = list(train_idx), list(valid_idx)\n",
    "        train_loader = DataLoader(TensorDataset(train_x_t[train_idx, :], train_y_t[train_idx]),\n",
    "                                  shuffle=True, drop_last=True, **LOADER_PARAM)\n",
    "        valid_loader = DataLoader(TensorDataset(train_x_t[valid_idx, :], train_y_t[valid_idx]),\n",
    "                                  shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "        test_loader = DataLoader(TensorDataset(test_x_t, torch.zeros((test_len,), dtype=torch.float32)),\n",
    "                                 shuffle=False, drop_last=False, **LOADER_PARAM)\n",
    "        model = nn.Sequential(\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(91, 180, bias=False),\n",
    "            nn.LeakyReLU(0.05, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(180, 32, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1)\n",
    "        ).to(DEVICE)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.20665], device=DEVICE))\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=5e-3, weight_decay=7.8e-2)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=N_EPOCH // 6, eta_min=4e-4)\n",
    "        prediction_t, loss_t = np.zeros((test_len, 1), dtype=np.float32), 1.\n",
    "\n",
    "        # for epoch in range(N_EPOCH):\n",
    "        for epoch in tqdm(range(N_EPOCH), desc='{:02d}/{:02d}'.format(skfold + 1, N_SKFOLD)):\n",
    "            model.train()\n",
    "            for idx, (xx, yy) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "                pred = model(xx).squeeze()\n",
    "                loss = criterion(pred, yy)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step(epoch + idx / len(train_loader))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                running_acc, running_loss, running_count = 0, 0., 0\n",
    "                for xx, yy in valid_loader:\n",
    "                    xx, yy = xx.to(DEVICE), yy.to(DEVICE)\n",
    "                    pred = model(xx).squeeze()\n",
    "                    loss = criterion(pred, yy)\n",
    "                    running_loss += loss.item() * len(yy)\n",
    "                    running_count += len(yy)\n",
    "                    running_acc += ((torch.sigmoid(pred) > 0.5).float() == yy).sum().item()\n",
    "                # print('R{:02d} S{:02d} E{:02d} | {:6.4f}, {:5.2f}%'\n",
    "                #       .format(repeat + 1, skfold + 1, epoch + 1, running_loss / running_count,\n",
    "                #               running_acc / running_count * 100))\n",
    "\n",
    "                if running_loss / running_count < loss_t:\n",
    "                    loss_t = running_loss / running_count\n",
    "                    for idx, (xx, _) in enumerate(test_loader):\n",
    "                        xx = xx.to(DEVICE)\n",
    "                        pred = (2. - torch.sigmoid(model(xx).detach().to('cpu'))).numpy()\n",
    "                        prediction_t[BATCH_SIZE * idx:min(BATCH_SIZE * (idx + 1), len(prediction)), :] \\\n",
    "                            = pred[:, :].copy()\n",
    "        prediction[:, :] += prediction_t[:, :].copy() / (N_REPEAT * N_SKFOLD)\n",
    "        tot += loss_t\n",
    "    print('R{} -> {:6.4f}'.format(repeat + 1, tot / N_SKFOLD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
